{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d3d39b",
   "metadata": {},
   "source": [
    "## Import library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4f4049cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from string import digits\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense,Embedding, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model,load_model, model_from_json\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle as pkl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b46524",
   "metadata": {},
   "source": [
    "## Load Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e5e7d5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Smit\\AppData\\Local\\Temp\\ipykernel_13256\\1719177825.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data= pd.read_csv(\"hin.txt\", delimiter='\\t', error_bad_lines=False, header=None, names=['english', 'hindi',\"utf-8\"],)\n"
     ]
    }
   ],
   "source": [
    "data= pd.read_csv(\"hin.txt\", delimiter='\\t', error_bad_lines=False, header=None, names=['english', 'hindi',\"utf-8\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0ebd9537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "      <th>utf-8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Wow!</td>\n",
       "      <td>वाह!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Duck!</td>\n",
       "      <td>झुको!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Duck!</td>\n",
       "      <td>बतख़!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Help!</td>\n",
       "      <td>बचाओ!</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Jump.</td>\n",
       "      <td>उछलो.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>2974</td>\n",
       "      <td>If you go to that supermarket, you can buy mos...</td>\n",
       "      <td>उस सूपरमार्केट में तुम लगभग कोई भी रोजाने में ...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>2975</td>\n",
       "      <td>The passengers who were injured in the acciden...</td>\n",
       "      <td>जिन यात्रियों को दुर्घटना मे चोट आई थी उन्हे अ...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>2976</td>\n",
       "      <td>Democracy is the worst form of government, exc...</td>\n",
       "      <td>लोकतंत्र सरकार का सबसे घिनौना रूप है, अगर बाकी...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>2977</td>\n",
       "      <td>If my boy had not been killed in the traffic a...</td>\n",
       "      <td>अगर मेरा बेटा ट्रेफ़िक हादसे में नहीं मारा गया...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>2978</td>\n",
       "      <td>When I was a kid, touching bugs didn't bother ...</td>\n",
       "      <td>जब मैं बच्चा था, मुझे कीड़ों को छूने से कोई पर...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2979 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                            english  \\\n",
       "0         0                                               Wow!   \n",
       "1         1                                              Duck!   \n",
       "2         2                                              Duck!   \n",
       "3         3                                              Help!   \n",
       "4         4                                              Jump.   \n",
       "...     ...                                                ...   \n",
       "2974   2974  If you go to that supermarket, you can buy mos...   \n",
       "2975   2975  The passengers who were injured in the acciden...   \n",
       "2976   2976  Democracy is the worst form of government, exc...   \n",
       "2977   2977  If my boy had not been killed in the traffic a...   \n",
       "2978   2978  When I was a kid, touching bugs didn't bother ...   \n",
       "\n",
       "                                                  hindi  \\\n",
       "0                                                  वाह!   \n",
       "1                                                 झुको!   \n",
       "2                                                 बतख़!   \n",
       "3                                                 बचाओ!   \n",
       "4                                                 उछलो.   \n",
       "...                                                 ...   \n",
       "2974  उस सूपरमार्केट में तुम लगभग कोई भी रोजाने में ...   \n",
       "2975  जिन यात्रियों को दुर्घटना मे चोट आई थी उन्हे अ...   \n",
       "2976  लोकतंत्र सरकार का सबसे घिनौना रूप है, अगर बाकी...   \n",
       "2977  अगर मेरा बेटा ट्रेफ़िक हादसे में नहीं मारा गया...   \n",
       "2978  जब मैं बच्चा था, मुझे कीड़ों को छूने से कोई पर...   \n",
       "\n",
       "                                                  utf-8  \n",
       "0     CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "1     CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "2     CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "3     CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "4     CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "...                                                 ...  \n",
       "2974  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "2975  CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "2976  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "2977  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "2978  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "\n",
       "[2979 rows x 4 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reset_index(level=0, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ee4a5930",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['english', 'hindi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f0d53b99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>वाह!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>झुको!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>बतख़!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help!</td>\n",
       "      <td>बचाओ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>उछलो.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>If you go to that supermarket, you can buy mos...</td>\n",
       "      <td>उस सूपरमार्केट में तुम लगभग कोई भी रोजाने में ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>The passengers who were injured in the acciden...</td>\n",
       "      <td>जिन यात्रियों को दुर्घटना मे चोट आई थी उन्हे अ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>Democracy is the worst form of government, exc...</td>\n",
       "      <td>लोकतंत्र सरकार का सबसे घिनौना रूप है, अगर बाकी...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>If my boy had not been killed in the traffic a...</td>\n",
       "      <td>अगर मेरा बेटा ट्रेफ़िक हादसे में नहीं मारा गया...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>When I was a kid, touching bugs didn't bother ...</td>\n",
       "      <td>जब मैं बच्चा था, मुझे कीड़ों को छूने से कोई पर...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2979 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                english  \\\n",
       "0                                                  Wow!   \n",
       "1                                                 Duck!   \n",
       "2                                                 Duck!   \n",
       "3                                                 Help!   \n",
       "4                                                 Jump.   \n",
       "...                                                 ...   \n",
       "2974  If you go to that supermarket, you can buy mos...   \n",
       "2975  The passengers who were injured in the acciden...   \n",
       "2976  Democracy is the worst form of government, exc...   \n",
       "2977  If my boy had not been killed in the traffic a...   \n",
       "2978  When I was a kid, touching bugs didn't bother ...   \n",
       "\n",
       "                                                  hindi  \n",
       "0                                                  वाह!  \n",
       "1                                                 झुको!  \n",
       "2                                                 बतख़!  \n",
       "3                                                 बचाओ!  \n",
       "4                                                 उछलो.  \n",
       "...                                                 ...  \n",
       "2974  उस सूपरमार्केट में तुम लगभग कोई भी रोजाने में ...  \n",
       "2975  जिन यात्रियों को दुर्घटना मे चोट आई थी उन्हे अ...  \n",
       "2976  लोकतंत्र सरकार का सबसे घिनौना रूप है, अगर बाकी...  \n",
       "2977  अगर मेरा बेटा ट्रेफ़िक हादसे में नहीं मारा गया...  \n",
       "2978  जब मैं बच्चा था, मुझे कीड़ों को छूने से कोई पर...  \n",
       "\n",
       "[2979 rows x 2 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c646ef9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1358340, 1358340)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_text = language_data['english'].values\n",
    "hindi_text = language_data['hindi'].values\n",
    "len(english_text), len(hindi_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacb0806",
   "metadata": {},
   "source": [
    "## Data Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "90f050f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Smit\\AppData\\Local\\Temp\\ipykernel_13256\\1641608552.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"english\"] = data[\"english\"].str.lower()\n",
      "C:\\Users\\Smit\\AppData\\Local\\Temp\\ipykernel_13256\\1641608552.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"hindi\"] = data[\"hindi\"].str.lower()\n"
     ]
    }
   ],
   "source": [
    "data[\"english\"] = data[\"english\"].str.lower()\n",
    "data[\"hindi\"] = data[\"hindi\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "df3818b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing inverted commas\n",
    "english_text_ = [re.sub(\"'\",'',x) for x in data[\"english\"] ]\n",
    "hindi_text_ = [re.sub(\"'\",'',x) for x in data[\"hindi\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2048b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text_list):\n",
    "  table = str.maketrans('', '', string.punctuation)\n",
    "  removed_punc_text = []\n",
    "  for sent in text_list:\n",
    "    sentance = [w.translate(table) for w in sent.split(' ')]\n",
    "    removed_punc_text.append(' '.join(sentance))\n",
    "  return removed_punc_text\n",
    "english_text_ = remove_punc(english_text_)\n",
    "hindi_text_ = remove_punc(hindi_text_)\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "removed_digits_text = []\n",
    "for sent in english_text_:\n",
    "  sentance = [w.translate(remove_digits) for w in sent.split(' ')]\n",
    "  removed_digits_text.append(' '.join(sentance))\n",
    "english_text_ = removed_digits_text\n",
    "# removing the digits from the marathi sentances\n",
    "hindi_text_ = [re.sub(\"[२३०८१५७९४६]\",\"\",x) for x in hindi_text_]\n",
    "hindi_text_ = [re.sub(\"[\\u200d]\",\"\",x) for x in hindi_text_]\n",
    "# removing the stating and ending whitespaces\n",
    "english_text_ = [x.strip() for x in english_text_]\n",
    "hindi_text_ = [x.strip() for x in hindi_text_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5232dd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start वाह end', 'wow')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting the start and end words in the marathi sentances\n",
    "hindi_text_ = [\"start \" + x + \" end\" for x in hindi_text_]\n",
    "# manipulated_marathi_text_\n",
    "hindi_text_[0], english_text_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c35455",
   "metadata": {},
   "source": [
    "## Data preparation for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5e5ae3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = english_text_\n",
    "Y = hindi_text_\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,Y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c12a55",
   "metadata": {},
   "source": [
    "### Let’s determine the maximum length of our sentences in both English and Hindi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3f1b4824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 22)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Max_length(data):\n",
    "  max_length_ = max([len(x.split(' ')) for x in data])\n",
    "  return max_length_\n",
    "#Training data\n",
    "max_length_english = Max_length(X_train)\n",
    "max_length_hindi = Max_length(y_train)\n",
    "#Test data\n",
    "max_length_english_test = Max_length(X_test)\n",
    "max_length_hindi_test = Max_length(y_test)\n",
    "max_length_hindi, max_length_english"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db99b37",
   "metadata": {},
   "source": [
    "### Tokenization And Padding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bfa5eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "englishTokenizer = Tokenizer()\n",
    "englishTokenizer.fit_on_texts(X_train)\n",
    "Eword2index = englishTokenizer.word_index\n",
    "vocab_size_source = len(Eword2index) + 1\n",
    "\n",
    "X_train = englishTokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length_english, padding='post')\n",
    "X_test = englishTokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen = max_length_english, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e7a12bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindiTokenizer = Tokenizer()\n",
    "hindiTokenizer.fit_on_texts(y_train)\n",
    "Mword2index = hindiTokenizer.word_index\n",
    "vocab_size_target = len(Mword2index) + 1\n",
    "\n",
    "y_train = hindiTokenizer.texts_to_sequences(y_train)\n",
    "y_train = pad_sequences(y_train, maxlen=max_length_hindi, padding='post')\n",
    "y_test = hindiTokenizer.texts_to_sequences(y_test)\n",
    "y_test = pad_sequences(y_test, maxlen = max_length_hindi, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8c44fa60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2273, 2896)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size_source, vocab_size_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c7f4495d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2,  54,   5, 426, 522, 124, 140,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  1,   9,  52, 153,  24,  17, 372, 584, 298,   2,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0]))"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3c0be9",
   "metadata": {},
   "source": [
    "## Save model\n",
    "To save our preprocessing time whenever we reuse it again in future, we will save our important attributes. So, let’s do it first with the help of pickle library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d1593f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NMT_data.pkl','wb') as f:\n",
    "  pkl.dump([X_train, y_train, X_test, y_test],f)\n",
    "with open('NMT_Etokenizer.pkl','wb') as f:\n",
    "  pkl.dump([vocab_size_source, Eword2index, englishTokenizer], f)\n",
    "with open('NMT_Mtokenizer.pkl', 'wb') as f:\n",
    "  pkl.dump([vocab_size_target, Mword2index, hindiTokenizer], f)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b4dea",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b6e2c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "logger = tf.get_logger()\n",
    "\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "\n",
    "        logger.debug(f\"encoder_out_seq.shape = {encoder_out_seq.shape}\")\n",
    "        logger.debug(f\"decoder_out_seq.shape = {decoder_out_seq.shape}\")\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            logger.debug(\"Running energy computation step\")\n",
    "\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                raise TypeError(f\"States must be an iterable. Got {states} of type {type(states)}\")\n",
    "\n",
    "            encoder_full_seq = states[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_full_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "\n",
    "            logger.debug(f\"U_a_dot_h.shape = {U_a_dot_h.shape}\")\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "\n",
    "            logger.debug(f\"Ws_plus_Uh.shape = {Ws_plus_Uh.shape}\")\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            logger.debug(f\"ei.shape = {e_i.shape}\")\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            logger.debug(\"Running attention vector computation step\")\n",
    "\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                raise TypeError(f\"States must be an iterable. Got {states} of type {type(states)}\")\n",
    "\n",
    "            encoder_full_seq = states[-1]\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_full_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "\n",
    "            logger.debug(f\"ci.shape = {c_i.shape}\")\n",
    "\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        # we don't maintain states between steps when computing attention\n",
    "        # attention is stateless, so we're passing a fake state for RNN step function\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e], constants=[encoder_out_seq]\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c], constants=[encoder_out_seq]\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1d2225f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 500\n",
    "# Encoder \n",
    "encoder_inputs = Input(shape=(max_length_english,)) \n",
    "enc_emb = Embedding(vocab_size_source, latent_dim,trainable=True)(encoder_inputs)\n",
    "#LSTM 1 \n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "#LSTM 2 \n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "#LSTM 3 \n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "# Set up the decoder. \n",
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(vocab_size_target, latent_dim,trainable=True) \n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "#LSTM using encoder_states as initial state\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "#Attention Layer\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "# Concat attention output and decoder LSTM output \n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "#Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(vocab_size_target, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "plot_model(model, to_file='train_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "172b2fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3230f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "965795ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 73s 2s/step - loss: 2.5568 - accuracy: 0.6857 - val_loss: 1.7802 - val_accuracy: 0.7189\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 54s 1s/step - loss: 1.9258 - accuracy: 0.7065 - val_loss: 1.7787 - val_accuracy: 0.7182\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 54s 1s/step - loss: 1.8294 - accuracy: 0.7181 - val_loss: 1.6110 - val_accuracy: 0.7522\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 54s 1s/step - loss: 1.7286 - accuracy: 0.7417 - val_loss: 1.5749 - val_accuracy: 0.7557\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 56s 1s/step - loss: 1.6975 - accuracy: 0.7428 - val_loss: 1.5582 - val_accuracy: 0.7565\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 56s 1s/step - loss: 1.6853 - accuracy: 0.7429 - val_loss: 1.5458 - val_accuracy: 0.7565\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 58s 1s/step - loss: 1.6694 - accuracy: 0.7437 - val_loss: 1.5283 - val_accuracy: 0.7596\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 59s 1s/step - loss: 1.6513 - accuracy: 0.7442 - val_loss: 1.5265 - val_accuracy: 0.7584\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 58s 1s/step - loss: 1.6323 - accuracy: 0.7451 - val_loss: 1.5130 - val_accuracy: 0.7594\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 56s 1s/step - loss: 1.6076 - accuracy: 0.7469 - val_loss: 1.4904 - val_accuracy: 0.7599\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 56s 1s/step - loss: 1.5886 - accuracy: 0.7486 - val_loss: 1.4783 - val_accuracy: 0.7642\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 56s 1s/step - loss: 1.5677 - accuracy: 0.7503 - val_loss: 1.4727 - val_accuracy: 0.7646\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 57s 1s/step - loss: 1.5460 - accuracy: 0.7522 - val_loss: 1.4604 - val_accuracy: 0.7673\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 57s 1s/step - loss: 1.5278 - accuracy: 0.7533 - val_loss: 1.4567 - val_accuracy: 0.7665\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 57s 1s/step - loss: 1.5080 - accuracy: 0.7551 - val_loss: 1.4589 - val_accuracy: 0.7652\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 59s 1s/step - loss: 1.4921 - accuracy: 0.7558 - val_loss: 1.4348 - val_accuracy: 0.7696\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 62s 1s/step - loss: 1.4735 - accuracy: 0.7569 - val_loss: 1.4295 - val_accuracy: 0.7696\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 69s 2s/step - loss: 1.4570 - accuracy: 0.7584 - val_loss: 1.4276 - val_accuracy: 0.7704\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 69s 2s/step - loss: 1.4410 - accuracy: 0.7593 - val_loss: 1.4226 - val_accuracy: 0.7722\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 70s 2s/step - loss: 1.4228 - accuracy: 0.7604 - val_loss: 1.4480 - val_accuracy: 0.7663\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train, y_train[:,:-1]], y_train.reshape(y_train.shape[0], y_train.shape[1],1)[:,1:], \n",
    "                    epochs=20,\n",
    "                    batch_size=64,\n",
    "                    validation_data = ([X_test, y_test[:,:-1]],           \n",
    "                    y_test.reshape(y_test.shape[0], y_test.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d65dbb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 22, 500)      1136500     ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_12 (LSTM)                 [(None, 22, 500),    2002000     ['embedding_6[0][0]']            \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_13 (LSTM)                 [(None, 22, 500),    2002000     ['lstm_12[0][0]']                \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, None, 500)    1448000     ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_14 (LSTM)                 [(None, 22, 500),    2002000     ['lstm_13[0][0]']                \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " lstm_15 (LSTM)                 [(None, None, 500),  2002000     ['embedding_7[0][0]',            \n",
      "                                 (None, 500),                     'lstm_14[0][1]',                \n",
      "                                 (None, 500)]                     'lstm_14[0][2]']                \n",
      "                                                                                                  \n",
      " attention_layer (AttentionLaye  ((None, None, 500),  500500     ['lstm_14[0][0]',                \n",
      " r)                              (None, None, 22))                'lstm_15[0][0]']                \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, None, 1000)   0           ['lstm_15[0][0]',                \n",
      "                                                                  'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, None, 2896)  2898896     ['concat_layer[0][0]']           \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,991,896\n",
      "Trainable params: 13,991,896\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d70f3777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot \n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e249b45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"NMT_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"NMT_model_weight.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7e120dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model architecture and asigning the weights\n",
    "json_file = open('NMT_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_loaded = model_from_json(loaded_model_json, custom_objects={'AttentionLayer': AttentionLayer})\n",
    "# load weights into new model\n",
    "model_loaded.load_weights(\"NMT_model_weight.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "1fddfc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=500\n",
    "# encoder inference\n",
    "encoder_inputs = model_loaded.input[0]  #loading encoder_inputs\n",
    "encoder_outputs, state_h, state_c = model_loaded.layers[6].output #loading encoder_outputs\n",
    "#print(encoder_outputs.shape)\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "# decoder inference\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(22,latent_dim))\n",
    "# Get the embeddings of the decoder sequence\n",
    "decoder_inputs = model_loaded.layers[3].output\n",
    "#print(decoder_inputs.shape)\n",
    "dec_emb_layer = model_loaded.layers[5]\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_lstm = model_loaded.layers[7]\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "#attention inference\n",
    "attn_layer = model_loaded.layers[8]\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "concate = model_loaded.layers[9]\n",
    "decoder_inf_concat = concate([decoder_outputs2, attn_out_inf])\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_dense = model_loaded.layers[10]\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "1d0d7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate an empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    \n",
    "    # Choose the 'start' word as the first word of the target sequence.\n",
    "    target_seq[0, 0] = Mword2index['start']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        \n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = Mindex2word[sampled_token_index]\n",
    "        \n",
    "        if sampled_token != 'end':\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "        \n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if sampled_token == 'end' or len(decoded_sentence.split()) >= (21 - 1):\n",
    "            stop_condition = True\n",
    "        \n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "    \n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "02ae5232",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eindex2word = englishTokenizer.index_word\n",
    "Mindex2word = hindiTokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "e24b2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if((i!=0 and i!=Mword2index['start']) and i!=Mword2index['end']):\n",
    "        newString=newString+Mindex2word[i]+' '\n",
    "    return newString\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if(i!=0):\n",
    "        newString=newString+Eindex2word[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "547ffe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: we dont know where we are \n",
      "Original summary: हमें नहीं पता हम कहाँ हैं। \n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted summary:  हम बहुत बहुत बहुत बहुत बहुत बहुत हैं।\n",
      "\n",
      "\n",
      "Review: they abandoned their country \n",
      "Original summary: उन्होंने अपने देश को दिया। \n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted summary:  हम बहुत बहुत बहुत बहुत बहुत हैं।\n",
      "\n",
      "\n",
      "Review: he is less than his father \n",
      "Original summary: उसके पिता जितनी नहीं है। \n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Predicted summary:  वह पास बहुत बहुत बहुत बहुत नहीं है।\n",
      "\n",
      "\n",
      "Review: who was the letter written to \n",
      "Original summary: पत्र किसको लिखा गया था \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicted summary:  वह बहुत बहुत बहुत बहुत बहुत बहुत है।\n",
      "\n",
      "\n",
      "Review: no in sight \n",
      "Original summary: आसपास कोई नहीं है। \n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicted summary:  वह बहुत बहुत बहुत है।\n",
      "\n",
      "\n",
      "Review: he was buried in this graveyard \n",
      "Original summary: उसको इस कब्रिस्तान में बरी किया गया था। \n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicted summary:  वह एक बहुत बहुत बहुत बहुत बहुत है।\n",
      "\n",
      "\n",
      "Review: he is after a job \n",
      "Original summary: वह किसी नौकरी के पीछे है। \n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicted summary:  वह बहुत बहुत बहुत बहुत बहुत है।\n",
      "\n",
      "\n",
      "Review: how about the taste \n",
      "Original summary: और स्वाद कैसा है \n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicted summary:  वह बहुत बहुत बहुत बहुत बहुत है।\n",
      "\n",
      "\n",
      "Review: tom \n",
      "Original summary: टॉम ने ली । \n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicted summary:  यह बहुत बहुत है।\n",
      "\n",
      "\n",
      "Review: were you shot \n",
      "Original summary: क्या तुम्हें गोली लग गई थी \n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted summary:  वह बहुत बहुत बहुत बहुत है।\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):  \n",
    "  print(\"Review:\",seq2text(X_test[i]))\n",
    "  print(\"Original summary:\",seq2summary(y_test[i]))\n",
    "  print(\"Predicted summary:\",decode_sequence(X_test[i].reshape(1,22)))\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d537fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
